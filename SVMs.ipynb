{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "021f364c",
   "metadata": {},
   "source": [
    "# Support Vector Machines\n",
    "\n",
    "This notebook contains sample code to classify digits using the MNIST Dataset and the solutions to **Chapter 5 assignment.**\n",
    "\n",
    "A Support Vector Machine (SVM) is a powerful and versatile Machine Learning\n",
    "model, capable of performing linear or nonlinear classification, regression, and even\n",
    "outlier detection. It is one of the most popular models in Machine Learning, and any‐\n",
    "one interested in Machine Learning should have it in their toolbox. SVMs are partic‐\n",
    "ularly well suited for classification of complex small- or medium-sized datasets.\n",
    "\n",
    "This chapter will explain the core concepts of SVMs, how to use them, and how they\n",
    "work.\n",
    "\n",
    "**About Dataset:**\n",
    "\n",
    "The MNIST dataset contains 70,000 small images of digits handwritten by high school students and employees of the US Census Bureau. Each image is labeled with the digit it represents.\n",
    "\n",
    "**Credit:**\n",
    "\n",
    "O'Reilly book Hands-on Machine Learning with Scikit-Learn, Keras and TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ba3670",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1620d02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc4f070",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371edc8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9eff7c90",
   "metadata": {},
   "source": [
    "# Assignment 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ce10d0",
   "metadata": {},
   "source": [
    "1. What is the fundamental idea behind Support Vector Machines?\n",
    "2. What is a support vector?\n",
    "3. Why is it important to scale the inputs when using SVMs?\n",
    "4. Can an SVM classifier output a confidence score when it classifies an instance?\n",
    "What about a probability?\n",
    "5. Should you use the primal or the dual form of the SVM problem to train a model\n",
    "on a training set with millions of instances and hundreds of features?\n",
    "6. Say you’ve trained an SVM classifier with an RBF kernel, but it seems to underfit\n",
    "the training set. Should you increase or decrease γ (gamma)? What about C?\n",
    "7. How should you set the QP parameters (H, f, A, and b) to solve the soft margin\n",
    "linear SVM classifier problem using an off-the-shelf QP solver?\n",
    "8. Train a LinearSVC on a linearly separable dataset. Then train an SVC and a\n",
    "SGDClassifier on the same dataset. See if you can get them to produce roughly\n",
    "the same model.\n",
    "9. Train an SVM classifier on the MNIST dataset. Since SVM classifiers are binary\n",
    "classifiers, you will need to use one-versus-the-rest to classify all 10 digits. You\n",
    "may want to tune the hyperparameters using small validation sets to speed up the\n",
    "process. What accuracy can you reach?\n",
    "10. Train an SVM regressor on the California housing dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b81c3a",
   "metadata": {},
   "source": [
    "# Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9effe3f5",
   "metadata": {},
   "source": [
    "1. The fundamental idea behind Support Vector Machines is to fit the widest possi‐\n",
    "ble “street” between the classes. In other words, the goal is to have the largest pos‐\n",
    "sible margin between the decision boundary that separates the two classes and\n",
    "the training instances. When performing soft margin classification, the SVM\n",
    "searches for a compromise between perfectly separating the two classes and hav‐\n",
    "ing the widest possible street (i.e., a few instances may end up on the street).\n",
    "Another key idea is to use kernels when training on nonlinear datasets.\n",
    "2. After training an SVM, a support vector is any instance located on the “street” (see\n",
    "the previous answer), including its border. The decision boundary is entirely\n",
    "determined by the support vectors. Any instance that is not a support vector (i.e.,\n",
    "is off the street) has no influence whatsoever; you could remove them, add more\n",
    "instances, or move them around, and as long as they stay off the street they won’t\n",
    "affect the decision boundary. Computing the predictions only involves the sup‐\n",
    "port vectors, not the whole training set.\n",
    "\n",
    "3. SVMs try to fit the largest possible “street” between the classes (see the first\n",
    "answer), so if the training set is not scaled, the SVM will tend to neglect small\n",
    "features (see Figure 5-2).\n",
    "4. An SVM classifier can output the distance between the test instance and the deci‐\n",
    "sion boundary, and you can use this as a confidence score. However, this score\n",
    "cannot be directly converted into an estimation of the class probability. If you set\n",
    "probability=True when creating an SVM in Scikit-Learn, then after training it\n",
    "will calibrate the probabilities using Logistic Regression on the SVM’s scores\n",
    "(trained by an additional five-fold cross-validation on the training data). This\n",
    "will add the predict_proba() and predict_log_proba() methods to the SVM.\n",
    "5. This question applies only to linear SVMs since kernelized SVMs can only use\n",
    "the dual form. The computational complexity of the primal form of the SVM\n",
    "problem is proportional to the number of training instances m, while the compu‐\n",
    "tational complexity of the dual form is proportional to a number between m2\n",
    " and\n",
    "m3\n",
    ". So if there are millions of instances, you should definitely use the primal\n",
    "form, because the dual form will be much too slow.\n",
    "6. If an SVM classifier trained with an RBF kernel underfits the training set, there\n",
    "might be too much regularization. To decrease it, you need to increase gamma or C\n",
    "(or both).\n",
    "7. Let’s call the QP parameters for the hard margin problem H′, f′, A′, and b′ (see\n",
    "“Quadratic Programming” on page 167). The QP parameters for the soft margin\n",
    "problem have m additional parameters (np = n + 1 + m) and m additional con‐\n",
    "straints (nc\n",
    " = 2m). They can be defined like so:\n",
    " \n",
    " • H is equal to H′, plus m columns of 0s on the right and m rows of 0s at the\n",
    "bottom: H =\n",
    "H′ 0 ⋯\n",
    "0 0\n",
    "ۇٴ ⋮\n",
    "• f is equal to f′ with m additional elements, all equal to the value of the hyper‐\n",
    "parameter C.\n",
    "• b is equal to b′ with m additional elements, all equal to 0.\n",
    "• A is equal to A′, with an extra m × m identity matrix Im appended to the right,\n",
    "–*I*m just below it, and the rest filled with 0s: A =\n",
    "A′ Im\n",
    "0 −Im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71414160",
   "metadata": {},
   "outputs": [],
   "source": [
    "For the solutions to exercises 8, 9, and 10, please see the Jupyter notebooks available\n",
    "at https://github.com/ageron/handson-ml2."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
